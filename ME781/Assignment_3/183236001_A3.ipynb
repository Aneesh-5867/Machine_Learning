{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "183236001_A3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCHr79wDAJ9EPBLmBDbvW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SudhakarKuma/Machine_Learning/blob/master/ME781/Assignment_3/183236001_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP1a2LolORJZ"
      },
      "source": [
        "# Finding Dissimilarity Measures "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSYrcBTAOKEo"
      },
      "source": [
        "## Instructions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ia0CeMfPpxM"
      },
      "source": [
        "1. Create a Python function to calculate the dissimilarity and similarity between two data points. This function should take 2 data points and a dissimilarity/ similarity abbreviation as inputs. Accordingly, it should return both the dissimilarity and similarity (corresponding to the acronym) between the data points. Please note that the function should be robust to the inappropriate inputs. The Python function should have methods to calculate the following dissimilarity/ similarity measures.\n",
        "\n",
        "Dissimilarity/ Similarity measure | Abbreviation\n",
        "--- | ---\n",
        "Euclidean norm | EN\n",
        "Frobenius or Hilbert Schmidt norm | HSN\n",
        "Diagonal norm | DN\n",
        "Mahalanobis norm | MN\n",
        "Lebesgue or Minkowski norm | LMN\n",
        "Cosine | CS\n",
        "Overlap | OS\n",
        "Dice | DS\n",
        "Jaccard | JS\n",
        "\n",
        "2. Create a function (with test cases) to perform unit testing of the function (mentioned in the first point) for five different assertions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsOUERI3Ss4L"
      },
      "source": [
        "## Mathematical Equations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gaFlWgISx2H"
      },
      "source": [
        "1. **Euclidean norm** - It measures the Euclidean distance between two data points ($x$ and $y$) in the simple trigonometric way, as given below: \n",
        "\n",
        "  $EN(x, y) = \\sqrt{\\sum_{i = 1}^k (x_i - y_i)^2}$\n",
        "\n",
        "  When data is dense or continuous, this is the best proximity measure. The Euclidean distance between two points is the length of the path connecting them. The Pythagorean theorem gives this distance between two points. \n",
        "\n",
        "  Reference: \n",
        "  * http://www.ashukumar27.io/similarity_functions/\n",
        "\n",
        "\n",
        "2. **Frobenius norm** - It is the matrix norm of an $m \\times n$ matrix $A$, which is defined as the square root of the sum of the absolute squares of its elements, as given below. \n",
        "\n",
        "  $|| A ||_F = \\sqrt{\\sum_{i = i}^m \\sum_{j = 1}^n |a_{ij}|^2}$\n",
        "\n",
        "  Reference: \n",
        "  * https://mathworld.wolfram.com/FrobeniusNorm.html\n",
        "\n",
        "3. **Diagonal norm** - For two data points ($x$ and $y$) and a diagonal matrix ($d$), diagonal norm (DN) can be calculated as given below:\n",
        "\n",
        "  $DN = \\sqrt{\\sum_{i = 1}^k d_i(x_i - y_i)^2}$\n",
        "\n",
        "  Reference:\n",
        "  * https://www.cis.upenn.edu/~cis515/cis515-11-sl4.pdf\n",
        "\n",
        "4. **Mahalanobis norm** -  It is a useful multivariate distance metric that measures the distance between a point (vector) and a distribution. Euclidean norm will work great as long as the features are equally weighted and are independent of each other. That is, if the attributes (columns in the dataset) are correlated to one another, which is typically the case in real-world datasets, the Euclidean distance between a point and the center of the points (distribution) can give little or misleading information about how close a point is to the cluster. \n",
        "\n",
        "  The formula to compute Mahalanobis norm (MN) is as follows:\n",
        "  \n",
        "  ${MN}^2 = (x - m)^T \\sum^{-1} (x - m)$\n",
        "\n",
        "  where, \n",
        "\n",
        "  $x$ is the vector of the observation (row in a dataset).\n",
        "\n",
        "  $m$ is the vector of mean values of independent variables (mean of each column). \n",
        "\n",
        "  $\\sum$ is the inverse covariance matrix of independent variables.\n",
        "\n",
        "  Reference:\n",
        "  * https://www.machinelearningplus.com/statistics/mahalanobis-distance/\n",
        "  * https://www.youtube.com/watch?v=4buOoXp7AyI\n",
        "  * http://www.cleartheconcepts.com/dm-similarity-dissimilarity-measure/   \n",
        "\n",
        "\n",
        "5. **Minkowski norm** - The  Euclidean norm is generalized by the Minkowski norm, as shown below: \n",
        "\n",
        "  $LMN(x, y) =\\bigg({\\sum_{i = 1}^k |x_i - y_i| ^ r}\\bigg) ^ {1/r}$\n",
        "\n",
        "  where $r$ is a parameter. \n",
        "\n",
        "  Reference:\n",
        "  * https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy \n",
        "\n",
        "6. **Cosine similarity** - This metric finds the normalized dot product of the two attributes. By determining the cosine similarity, we find out the cosine of the angle between the two objects. The cosine of 0° is 1, and it is less than or equal to 1 for any other angle. It is thus a judgment of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude. \n",
        "\n",
        "  This similarity (CS) between two data points ($x$ and $y$) is calculated as follows: \n",
        "\n",
        "  $CS (x, y) = \\frac{\\sum_{i = 1}^p x_i y_i}{\\sqrt{\\sum_{i = 1}^p (x_i)^2 (y_i)^2}}$  \n",
        "\n",
        "  Reference:\n",
        "  * http://www.ashukumar27.io/similarity_functions/ \n",
        "\n",
        "\n",
        "7. **Overlap similarity** (OS) - This metric is evaluated as follows: \n",
        "\n",
        "  $OS (x, y) = \\frac{\\sum_{i = 1}^p x_i y_i}{min\\big(\\sum_{i = 1}^p (x_i)^2, \\; \\sum_{i = 1}^p (y_i)^2  \\big)}$ \n",
        "\n",
        "8. **Dice similarity** (DS) - This metric is evaluated as follows: \n",
        "\n",
        "  $DS (x, y) = \\frac{2 \\sum_{i = 1}^p x_i y_i}{\\sum_{i = 1}^p (x_i)^2 \\; + \\; \\sum_{i = 1}^p (y_i)^2}$ \n",
        "\n",
        "9. **Jaccard similarity** - The Jaccard Similarity $JS$ is evaluated as follows: \n",
        "\n",
        "  $JS (x, y) = \\frac{\\sum_{i = 1}^p x_i y_i}{\\sum_{i = 1}^p (x_i)^2 \\; + \\; \\sum_{i = 1}^p (y_i)^2 \\; - \\; \\sum_{i = 1}^p x_i y_i}$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnkUHi_Aq0m-"
      },
      "source": [
        "## Python Scripts for Calculating Measures "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4lfuq0q73i"
      },
      "source": [
        "From the mathematical equations, we can observe that the norms take the inputs as given below:\n",
        "\n",
        "Norm | Input args\n",
        "--- | ---\n",
        "Euclidean | two vectors ($x$ and $y$)\n",
        "Minkowski | two vectors ($x$ and $y$) and one integer ($r$)\n",
        "Diagonal | two vectors ($x$ and $y$) and a diagonal matrix ($d$)\n",
        "Cosine | two vectors ($x$ and $y$)\n",
        "Overlap | two vectors ($x$ and $y$)\n",
        "Dice | two vectors ($x$ and $y$)\n",
        "Jaccard | two vectors ($x$ and $y$)\n",
        "Frobenius | a matrix \n",
        "Mahalanobis | two vectors ($x$ and $y$) and one covariance matrix \n",
        "\n",
        "Therefore, I will write three Python function, which will calculate the norms as given below:\n",
        "\n",
        "1. `vector_norms()` - Calculates Euclidean, Minkowski, Diagonal, Cosine, Overlap, Dice, and Jaccard. \n",
        "\n",
        "2. `frobenius_norm()` - Calculates Frobenius\n",
        "\n",
        "3. `mahalanobis_dist()` - Calculates Mahalanobis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAR5Vnx-BVOu"
      },
      "source": [
        "### `vector_norms()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjDxAVTJS1Zh",
        "outputId": "c11d03fc-034f-47b6-c67c-e6b07cf06795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file vector_norms.py\n",
        "\n",
        "# Import all the necessary modules \n",
        "import math\n",
        "from math import*\n",
        "from decimal import Decimal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import distance\n",
        "\n",
        "def vector_norms(x, y, r, d = 0, identity = \"EN\"):\n",
        "\n",
        "  \"\"\" Returns dissimilarity between two numeric vectors x and y \n",
        "\n",
        "  Args:\n",
        "  x: numeric tuple. First input vector \n",
        "  y: numeric tuple. Second input vector \n",
        "  r: int. Degree needed for calculating Minkowski norm \n",
        "  identity: str. Identity to know which norm to calculate for x and y, as given below\n",
        "  \"EN\": Euclidean, \"LMN\": Minkowski, \"DN\": Diagonal, \"CS\": Cosine, \"OS\": Overlap, \n",
        "  \"DS\": Dice, \"JS\": Jaccard\n",
        "  d: array/matrix. A weight matrix needed to calculate the diagonal norm. Default value zero. \n",
        "\n",
        "  Returns: \n",
        "  dissimilarity: float or int. Dissimilarity measure between x and y (along with r)\n",
        "  similarity: float or int. Similarity measure between x and y (along with r)\n",
        "\n",
        "  It also returns a message, when the inputs are not entered as mentioned in Args.  \n",
        "\n",
        "  Caution: \n",
        "  Some of the norms (like CS) uses the product of the magnitudes of x and y in\n",
        "  its denomintator. So, we should avoid having a zero vector while calculating \n",
        "  these norms. \n",
        "  \"\"\"\n",
        "\n",
        "  ########## Check whether the inputs are entered in desired format ###########\n",
        "\n",
        "  ######## Check whether the identity is one among those defined above ########\n",
        "  if identity not in [\"EN\", \"LMN\", \"CS\", \"OS\", \"DN\", \"DS\", \"JS\"]:\n",
        "    print(\"You have entered the wrong identity!\")\n",
        "    return\n",
        "  \n",
        "  ################ Check whether the input vectors are tuples #################\n",
        "  if (isinstance(x, tuple) == False) or (isinstance(y, tuple) == False):\n",
        "    print(\"This functions accepts only tuples as x and y!\")\n",
        "    return\n",
        "\n",
        "  #################### Check whether the tuple x is numeric ###################\n",
        "  for valx in x:\n",
        "    if (isinstance(valx, float) == False) and (isinstance(valx, int) == False):\n",
        "      print(\"This function accept only numeric tuples as x and y!\")\n",
        "      return\n",
        "  \n",
        "  #################### Check whether the tuple y is numeric ###################\n",
        "  for valy in y:\n",
        "    if (isinstance(valy, float) == False) and (isinstance(valy, int) == False):\n",
        "      print(\"This function accept only numeric tuples as x and y!\")\n",
        "      return\n",
        "\n",
        "  ############ Check whether the input degree r is an integer #################\n",
        "  if (isinstance(r, int) == False): \n",
        "    print(\"This functions accepts only integers as r!\")\n",
        "    return\n",
        "\n",
        "\n",
        "  ############### Calculate norms as per the value of identity ################\n",
        "  \n",
        "  ################## Calculate Euclidean norm for x and y #####################\n",
        "  if (identity == \"EN\"):\n",
        "    dissimilarity = math.sqrt(sum(pow(a - b, 2) for a, b in zip(x, y)))\n",
        "  \n",
        "  ################ Calculate Minkowski norm for x, y, and r ###################\n",
        "  elif (identity == \"LMN\"):\n",
        "    def nth_root(value, n_root):\n",
        "      root_value = 1/float(n_root)\n",
        "      return  value ** root_value\n",
        "    dissimilarity = nth_root(sum(pow(abs(a - b), r) for a, b in zip(x, y)), r)\n",
        "\n",
        "  ################ Calculate Diagonal norm for x, y, and d ###################\n",
        "  elif (identity == \"DN\"):\n",
        "    dissimilarity = round(math.sqrt(sum(w*(pow(a - b, 2)) for a, b, w in zip(x, y, d))),3)\n",
        "\n",
        "  ################ Calculate Cosine dissimilarity for x and y #################\n",
        "  elif (identity == \"CS\"):\n",
        "    def square_rooted(m):\n",
        "      return round(sqrt(sum([a * a for a in m])), 3)\n",
        "    numerator = sum(a * b for a, b in zip(x, y))\n",
        "    denominator = square_rooted(x) * square_rooted(y)\n",
        "    dissimilarity = round(numerator/float(denominator), 3)\n",
        "\n",
        "  ############### Calculate Overlap dissimilarity for x and y #################\n",
        "  elif (identity == \"OS\"):\n",
        "    numerator = sum(a * b for a, b in zip(x, y))\n",
        "    denominator = min(sum([a * a for a in x]), sum([b * b for b in y]))\n",
        "    dissimilarity = round(numerator/denominator, 2)\n",
        "\n",
        "  ############### Calculate Dice dissimilarity for x and y ####################\n",
        "  elif (identity == \"DS\"):\n",
        "    numerator = 2 * sum(a * b for a, b in zip(x, y))\n",
        "    denominator = sum([a * a for a in x]) + sum([b * b for b in y])\n",
        "    dissimilarity = round(numerator/denominator, 2)\n",
        "\n",
        "  ################ Calculate Jaccard dissimilarity for x and y ################\n",
        "  elif (identity == \"JS\"):\n",
        "    numerator = sum(a * b for a, b in zip(x, y))\n",
        "    denominator = sum([a * a for a in x]) + sum([b * b for b in y]) - sum(a * b for a, b in zip(x, y))\n",
        "    dissimilarity = round(numerator/denominator, 3)\n",
        "\n",
        "  ########################## Calculate similarity #############################\n",
        "  similarity = 1 / (1 + dissimilarity) \n",
        "\n",
        "  ################### Return dissimilarity, similarity ########################\n",
        "  return dissimilarity, similarity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting vector_norms.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWLMcEqQZ97a"
      },
      "source": [
        "### Testing `vector_norms()` for Error Messages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2dO0yExaEFf"
      },
      "source": [
        "I have applied the following constraints on the input arguments: \n",
        "\n",
        "* The function `vector_norms` accepts two numeric tuples ($x$ and $y$). If $x$ or $y$ is not a numeric tuple, the program will throw a message. \n",
        "\n",
        "* The function `vector_norms`  accepts integers as the value of $r$.\n",
        "\n",
        "* The function `vector_norms` can only calculate the following norms if passed the suitable identity: \n",
        "\n",
        "Identity | Norm \n",
        "--- | ---\n",
        "\"EN\"| Euclidean\n",
        "\"LMN\" | Minkowski\n",
        "\"DN\" | Diagonal \n",
        "\"CS\" | Cosine\n",
        "\"OS\" | Overlap \n",
        "\"DS\" | Dice \n",
        "\"JS\" |Jaccard\n",
        "\n",
        "If we try to pass an identity other than those defined above, it will throw a message, `You have entered the wrong identity!`\n",
        "\n",
        "Now, we will call the function with a few right and a few wrong inputs, as given below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGMrLBfKcUap",
        "outputId": "8909e447-e7d7-4eb7-b346-8ccef6ab6f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from vector_norms import vector_norms\n",
        "\n",
        "# Pass a numeric tuple \n",
        "x = (1, 2, 3)\n",
        "y = (3, 4, 5)\n",
        "\n",
        "values = vector_norms(x, y, r = 2, identity=\"LMN\")\n",
        "\n",
        "if (values != None):\n",
        "  print(\"Dissimilarity of {} and {} is {}\".format(x, y, round(values[0], 2)))\n",
        "  print(\"Similarity of {} and {} is {}\".format(x, y, round(values[1], 2)))\n",
        "else:\n",
        "  print(\"The function didn't return any value. Please check your input!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dissimilarity of (1, 2, 3) and (3, 4, 5) is 3.46\n",
            "Similarity of (1, 2, 3) and (3, 4, 5) is 0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ycBcxvFcDAL",
        "outputId": "682408c5-fef6-46a2-a5d4-6fdd61105676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from vector_norms import vector_norms\n",
        "\n",
        "# Pass a non-numeric tuple \n",
        "x = (1, 'a', 3)\n",
        "y = (3, 4, 5)\n",
        "\n",
        "values = vector_norms(x, y, r = 2, identity=\"LMN\")\n",
        "\n",
        "if (values != None):\n",
        "  print(\"Dissimilarity of {} and {} is {}\".format(x, y, round(values[0], 2)))\n",
        "  print(\"Similarity of {} and {} is {}\".format(x, y, round(values[1], 2)))\n",
        "else:\n",
        "  print(\"The function didn't return any value. Please check your input!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This function accept only numeric tuples as x and y!\n",
            "The function didn't return any value. Please check your input!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lvm-V3PcZ8D",
        "outputId": "affcb79e-6860-40ae-c0d3-5796a655568f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from vector_norms import vector_norms\n",
        "\n",
        "# Pass a non-integer value of r \n",
        "x = (1, 2, 3)\n",
        "y = (3, 4, 5)\n",
        "\n",
        "values = vector_norms(x, y, r = 3.5, identity=\"LMN\")\n",
        "\n",
        "if (values != None):\n",
        "  print(\"Dissimilarity of {} and {} is {}\".format(x, y, round(values[0], 2)))\n",
        "  print(\"Similarity of {} and {} is {}\".format(x, y, round(values[1], 2)))\n",
        "else:\n",
        "  print(\"The function didn't return any value. Please check your input!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This functions accepts only integers as r!\n",
            "The function didn't return any value. Please check your input!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJJT3i1Ic0JQ",
        "outputId": "8afad283-e02d-4530-cfd9-43d8543e3520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from vector_norms import vector_norms\n",
        "\n",
        "# Pass an identity other than those defined above\n",
        "x = (1, 3, 3)\n",
        "y = (3, 6, 5)\n",
        "\n",
        "values = vector_norms(x, y, r = 2, identity=\"XY\")\n",
        "\n",
        "if (values != None):\n",
        "  print(\"Dissimilarity of {} and {} is {}\".format(x, y, round(values[0], 2)))\n",
        "  print(\"Similarity of {} and {} is {}\".format(x, y, round(values[1], 2)))\n",
        "else:\n",
        "  print(\"The function didn't return any value. Please check your input!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have entered the wrong identity!\n",
            "The function didn't return any value. Please check your input!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ioohl2jNlBr"
      },
      "source": [
        "### Testing `vector_norms()` via `Pytest`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L3qotVeNs1G"
      },
      "source": [
        "Now, I will write test cases for the function `vector_norms()`. As I have implemented all the norms from scratch, I will use the built-in Python packages (as much as possible) to check for the correctness of the norms. \n",
        "\n",
        "In Python, we have `scipy.spatial` which has all the functions required for calculating the norms, as given below:\n",
        "\n",
        "* `scipy.spatial.distance.euclidean(u, v)` - Computes the Euclidean distance between two 1-D arrays. \n",
        "\n",
        "* `scipy.spatial.distance.minkowski(u, v, p = 2, w = None)` - Computes the Minkowski distance between two 1-D arrays.\n",
        "\n",
        "* `scipy.spatial.distance.cosine(u, v, w = None)` - Computes the Cosine distance between 1-D arrays. It computes the distance and not the similarity. So, we must subtract the value from 1 to get the similarity.\n",
        "\n",
        "For the remaining norms, I have tested the examples given on http://www.cleartheconcepts.com/dm-similarity-dissimilarity-measure/ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5rceqFnG3ZX",
        "outputId": "ad303de6-6145-4ff0-a93a-539eaeb2891b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file test_vector_norms.py\n",
        "\n",
        "from vector_norms import vector_norms\n",
        "from scipy.spatial import distance\n",
        "\n",
        "############### Test Euclidean norm on two different inputs ###############\n",
        "def test_vector_norms_en_1():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (2, 1, 2, 3)\n",
        "  expected = (distance.euclidean(x, y), 1 / (1 + distance.euclidean(x, y)))\n",
        "  actual = vector_norms(x, y, r = 0, identity = \"EN\")\n",
        "  assert actual == expected \n",
        "\n",
        "def test_vector_norms_en_2():\n",
        "  x = (0, 0, 0, 0)\n",
        "  y = (0, 0, 0, 0)\n",
        "  expected = (distance.euclidean(x, y), 1 / (1 + distance.euclidean(x, y)))\n",
        "  actual = vector_norms(x, y, r = 0, identity = \"EN\")\n",
        "  assert actual == expected \n",
        "\n",
        "############### Test Minkowski norm on three different inputs ###############\n",
        "def test_vector_norms_lmn_1():\n",
        "  x = (1, 1, 0)\n",
        "  y = (0, 1, 0)\n",
        "  r = 1\n",
        "  expected = (distance.minkowski(x, y, r), 1 / (1 + distance.minkowski(x, y, r)))\n",
        "  actual = vector_norms(x, y, r, identity = \"LMN\")\n",
        "  assert actual == expected \n",
        "\n",
        "def test_vector_norms_lmn_2():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (2, 1, 2, 3)\n",
        "  r = 2\n",
        "  expected = (distance.minkowski(x, y, r), 1 / (1 + distance.minkowski(x, y, r))) \n",
        "  actual = vector_norms(x, y, r, identity = \"LMN\")\n",
        "  assert actual == expected \n",
        "\n",
        "def test_vector_norms_lmn_3():\n",
        "  x = (1, 0, 0)\n",
        "  y = (0, 1, 0)\n",
        "  r = 3\n",
        "  expected = (distance.minkowski(x, y, r), 1 / (1 + distance.minkowski(x, y, r)))\n",
        "  actual = vector_norms(x, y, r, identity = \"LMN\")\n",
        "  assert actual == expected \n",
        "\n",
        "################## Test Diagonal norm on one input ##################\n",
        "def test_vector_norms_dn():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (3, 1, 2, 1)\n",
        "  r = 0\n",
        "  expected = (2.646, 1/(1 + 2.646))\n",
        "  actual = vector_norms(x, y, r, identity = \"DN\", d = (1, 2, 1, 2))\n",
        "  assert actual == expected \n",
        "\n",
        "############### Test Cosine dissimilarity on two different inputs #############\n",
        "def test_vector_norms_cs_1():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (3, 1, 2, 1)\n",
        "  r = 0\n",
        "  expected = (1 - distance.cosine(x, y), 1 / (1 + (1 - distance.cosine(x, y))))\n",
        "  actual = vector_norms(x, y, r, identity = \"CS\")\n",
        "  assert actual == expected \n",
        "\n",
        "def test_vector_norms_cs_2():\n",
        "  x = (1, 1, 1, 1)\n",
        "  y = (1, 1, 1, 1)\n",
        "  r = 0\n",
        "  expected = (1 - distance.cosine(x, y), 1 / (1 + (1 - distance.cosine(x, y))))\n",
        "  actual = vector_norms(x, y, r, identity = \"CS\")\n",
        "  assert actual == expected \n",
        "\n",
        "############# Test Overlap dissimilarity on two different inputs ##############\n",
        "def test_vector_norms_os_1():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (3, 1, 2, 1)\n",
        "  r = 0\n",
        "  expected = (0.8, 1 / (1 + 0.8))\n",
        "  actual = vector_norms(x, y, r, identity = \"OS\")\n",
        "  assert actual == expected \n",
        "\n",
        "##################### Test Dice dissimilarity on one input ####################\n",
        "def test_vector_norms_ds_1():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (3, 1, 2, 1)\n",
        "  r = 0\n",
        "  expected = (0.8, 1 / (1 + 0.8))\n",
        "  actual = vector_norms(x, y, r, identity = \"DS\")\n",
        "  assert actual == expected \n",
        "\n",
        "################## Test Jaccard dissimilarity on one input ####################\n",
        "def test_vector_norms_js_1():\n",
        "  x = (1, 2, 3, 1)\n",
        "  y = (3, 1, 2, 1)\n",
        "  r = 0\n",
        "  expected = (0.667, 1 / (1 + 0.667))\n",
        "  actual = vector_norms(x, y, r, identity = \"JS\")\n",
        "  assert actual == expected "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_vector_norms.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JZcB6AMIVfN",
        "outputId": "958641f0-bee7-491e-8571-0180f6fa9c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# Run the pytest module \n",
        "!python -m pytest test_vector_norms.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.6.9, pytest-3.6.4, py-1.9.0, pluggy-0.7.1\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1\n",
            "collected 11 items                                                             \u001b[0m\n",
            "\n",
            "test_vector_norms.py ...........\u001b[36m                                         [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m========================== 11 passed in 0.84 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psmH5hrvdeL6"
      },
      "source": [
        "### `frobenius_norm()` function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CloXKm1AfaIw",
        "outputId": "25dc64f2-94a5-445a-abf2-12a4e19db8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file frobenius_norm.py\n",
        "\n",
        "# Import all the necessary modules \n",
        "import numpy as np\n",
        "import pandas as pdz\n",
        "\n",
        "def frobenius_norm(x):\n",
        "\n",
        "  \"\"\" Returns Frobenius norm of a matrix \n",
        "\n",
        "  Args:\n",
        "  x: matrix. The matrix whose Frobenius norm is to be calculated. \n",
        "\n",
        "  Returns: \n",
        "  dissimilarity: float or int. The Frobenius norm of x \n",
        "  similarity: float or int. 1 / (1 + dissimilarity)\n",
        "\n",
        "  Caution: \n",
        "  This function only excepts a matrix as input. If you are having an array, you\n",
        "  should apply reshape function before feeding it to the function.   \n",
        "  \"\"\"\n",
        "\n",
        "  #### Calculate the Frobenius norm using the built-in function of numpy ######\n",
        "  # https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html \n",
        "  dissimilarity = round(np.linalg.norm(x, 'fro'), 3)\n",
        "\n",
        "  ########################## Calculate similarity #############################\n",
        "  similarity = 1 / (1 + dissimilarity) \n",
        "\n",
        "  ################### Return dissimilarity, similarity ########################\n",
        "  return dissimilarity, similarity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting frobenius_norm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_VOvu9Wh2Po"
      },
      "source": [
        "### Testing `frobenius_norm()` via `Pytest`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd3LPyFxkOOQ"
      },
      "source": [
        "I have used the examples given on https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html for testing the `frobenius_norm()` function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hNOLplXiKLu",
        "outputId": "74c5608f-44be-4f52-96f7-8ff6405076d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file test_frobenius_norm.py\n",
        "\n",
        "from frobenius_norm import frobenius_norm\n",
        "import numpy as np\n",
        "\n",
        "############### Test Frobenius_norm on three different inputs ###############\n",
        "def test_frobenius_norm_1():\n",
        "  x = [[1, 0, 0],\n",
        "       [0, 1, 0],\n",
        "       [0, 0, 1]]\n",
        "  expected = (1.732, 1 / (1 + 1.732))\n",
        "  actual = frobenius_norm(x)\n",
        "  assert actual == expected \n",
        "\n",
        "def test_frobenius_norm_2():\n",
        "  x = [[-4, -3, -2],\n",
        "       [-1,  0,  1],\n",
        "       [ 2,  3,  4]]\n",
        "  expected = (7.746, 1 / (1 + 7.746))\n",
        "  actual = frobenius_norm(x)\n",
        "  assert actual == expected \n",
        "\n",
        "def test_frobenius_norm_3():\n",
        "  a = np.arange(9) - 4\n",
        "  b = a.reshape((3, 3))\n",
        "  expected = (7.746, 1 / (1 + 7.746))\n",
        "  actual = frobenius_norm(b)\n",
        "  assert actual == expected "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_frobenius_norm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AC-c17Gi4fI",
        "outputId": "552bf1e0-c16f-474c-dd44-22fb3607c75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!python -m pytest test_frobenius_norm.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.6.9, pytest-3.6.4, py-1.9.0, pluggy-0.7.1\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1\n",
            "collected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_frobenius_norm.py ...\u001b[36m                                               [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 3 passed in 0.36 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keYDSeHMkauI"
      },
      "source": [
        "### `mahalanobis_dist()` function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KCcX8FYmjyE",
        "outputId": "5951b8a8-cb30-484b-a75f-506fa113e974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file mahalanobis_dist.py\n",
        "\n",
        "# Import all the necessary modules \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def mahalanobis_dist(x, data): \n",
        "  \"\"\" Returns Mahalanobis distance between a data (vector) and a distribution\n",
        "\n",
        "  Args:\n",
        "  x: array. The input vector whose distance is to be calculated. \n",
        "  data: matrix. The input data with which the distance of x is to be calculated. \n",
        "\n",
        "  Returns: \n",
        "  dissimilarity: float or int. The Mahalanobis distance of x and data \n",
        "  similarity: float or int. 1 / (1 + dissimilarity)\n",
        "  \"\"\"\n",
        "\n",
        "  m =  np.mean(data, axis = 0) # calculate mean of the independent variables of data\n",
        "\n",
        "  x_minus_m = x - m  ## subtract x from m \n",
        "\n",
        "  data = np.transpose(data)\n",
        "  cov_M = np.cov(data, bias = False) # Evaluate the covariance matrix\n",
        "  inv_Cov_M = np.linalg.inv(cov_M) # Find the inverse covariance matrix\n",
        "\n",
        "  temp1 = np.dot(x_minus_m, inv_Cov_M) # Multiply the (x - m) and inverse of covariance matrix  \n",
        "  temp2 = np.dot(temp1, np.transpose(x_minus_m)) # Multiply (x-m)^T and the previous product \n",
        "  \n",
        "  dissimilarity = np.sqrt(np.reshape(temp2, -1)) # Evaluate the dissimilarity from the previous product \n",
        "\n",
        "  ########################## Calculate similarity #############################\n",
        "  similarity = 1 / (1 + dissimilarity) \n",
        "\n",
        "  ################### Return dissimilarity, similarity ########################\n",
        "  return dissimilarity, similarity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mahalanobis_dist.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gJeeNPjsAMd"
      },
      "source": [
        "### Testing `mahalanobis_dist()` via `Pytest`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0-0YNAqogk",
        "outputId": "bcb3d908-1ab6-45ac-90b3-dfaa8d1ad09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%file test_mahalanobis_dist.py\n",
        "\n",
        "from mahalanobis_dist import mahalanobis_dist\n",
        "import numpy as np\n",
        "\n",
        "############### Test mahalanobis_dist on two different inputs ###############\n",
        "def test_mahalanobis_dist_1():\n",
        "  x = np.array([[154,900, 80]]) \n",
        "  data = np.array([[1,\t100,\t10],\n",
        "                 [2,\t300,\t15],\n",
        "                 [4,\t200,\t20],\n",
        "                 [2,\t600,\t10],\n",
        "                 [5,\t100,\t30]])\n",
        "  expected = (321.166, round(1 / (1 + 321.166), 3))\n",
        "  values_from_fun = mahalanobis_dist(x, data)\n",
        "  actual = (round(*values_from_fun[0], 3), round(*values_from_fun[1], 3))\n",
        "  assert actual == expected \n",
        "\n",
        "############### Test mahalanobis_dist on two different inputs ###############\n",
        "def test_mahalanobis_dist_2():\n",
        "  x = np.array([[4, 500, 40]]) \n",
        "  data = np.array([[1,\t100,\t10],\n",
        "                 [2,\t300,\t15],\n",
        "                 [4,\t200,\t20],\n",
        "                 [2,\t600,\t10],\n",
        "                 [5,\t100,\t30]])\n",
        "  expected = (10.33, round(1 / (1 + 10.33), 3))\n",
        "  values_from_fun = mahalanobis_dist(x, data)\n",
        "  actual = (round(*values_from_fun[0], 3), round(*values_from_fun[1], 3))\n",
        "  assert actual == expected \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_mahalanobis_dist.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVNT3Mkfs6zO",
        "outputId": "e438b20b-1459-4417-87f4-1eac9a846594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!python -m pytest test_mahalanobis_dist.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.6.9, pytest-3.6.4, py-1.9.0, pluggy-0.7.1\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1\n",
            "collected 2 items                                                              \u001b[0m\n",
            "\n",
            "test_mahalanobis_dist.py ..\u001b[36m                                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 2 passed in 0.36 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}